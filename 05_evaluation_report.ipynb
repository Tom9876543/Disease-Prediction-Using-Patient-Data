{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c43a6eb3",
   "metadata": {},
   "source": [
    "# Step 5 — Evaluation & One‑Page Report (Cleveland Heart Dataset)\n",
    "\n",
    "**Objective.** Predict heart disease (binary) using the Cleveland dataset and compare two simple models (Logistic Regression, Random Forest) using **accuracy** as the primary metric.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9609b186",
   "metadata": {},
   "source": [
    "## Dataset & Preprocessing (summary)\n",
    "\n",
    "- **Source:** UCI ML Repository — Cleveland subset (processed file)\n",
    "- **Shape:** 303 rows × 14 columns\n",
    "- **Target:** `target` (0–4) → **binarized** to `target_bin` (0 = healthy, 1 = disease)\n",
    "\n",
    "**Preprocessing**\n",
    "- Missing values: `ca`, `thal` → **mode**; all other numeric features (except target) → **median**\n",
    "- Scaling: Min‑Max to [0, 1] on all features\n",
    "- Final feature set: 13 columns\n",
    "- Class balance: ~54% healthy, ~46% disease\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1215b617",
   "metadata": {},
   "source": [
    "## Results (from Step 4)\n",
    "\n",
    "- **Logistic Regression Accuracy:** 0.8525  \n",
    "- **Random Forest Accuracy:** 0.9016  \n",
    "- **Selected model (by accuracy):** **Random Forest**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b7639a",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "- Random Forest achieved higher accuracy (0.9016) than Logistic Regression (0.8525).\n",
    "- Given the **balanced** dataset, accuracy is a reasonable first metric.\n",
    "- In medical settings, also consider:\n",
    "  - **Recall (Sensitivity)** for the positive class (disease), to reduce false negatives.\n",
    "  - **Precision** to limit false positives.\n",
    "  - **F1‑score** as a balanced measure.\n",
    "- The confusion matrix and classification report above help validate that performance is not driven by class imbalance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1d3ce4",
   "metadata": {},
   "source": [
    "## Submission Checklist (Week 1)\n",
    "\n",
    "- [x] 01_load_and_explore.ipynb — loading, names, `info()`, `describe()`, missingness\n",
    "- [x] 02_preprocessing.ipynb — imputation, scaling, binary target, build `X`, `y`\n",
    "- [x] 03_eda.ipynb — class balance + quick plots + correlation heatmap\n",
    "- [x] 04_model_training.ipynb — Logistic Regression & Random Forest, accuracy comparison\n",
    "- [x] 05_evaluation_report.ipynb — this one‑pager summary with final results\n",
    "- [x] Push all notebooks + `data/` README to GitHub (private/public as allowed)\n",
    "- [x] Short LinkedIn post with problem, approach, and repo link\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb6f34f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pypandoc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpypandoc\u001b[39;00m\n\u001b[0;32m      3\u001b[0m pypandoc\u001b[38;5;241m.\u001b[39mconvert_text(\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweek1_report.md\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mread(),\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdf\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     extra_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--standalone\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m )\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pypandoc'"
     ]
    }
   ],
   "source": [
    "import pypandoc\n",
    "\n",
    "pypandoc.convert_text(\n",
    "    open(\"week1_report.md\").read(),\n",
    "    'pdf',\n",
    "    format='md',\n",
    "    outputfile='week1_report.pdf',\n",
    "    extra_args=['--standalone']\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
